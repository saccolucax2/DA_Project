{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Carica il dataset\n",
    "dataset = pd.read_csv(r\"dataset.csv\")\n",
    "\n",
    "dataset1 = dataset[dataset['indic_bt'] == 'CONST']\n",
    "\n",
    "# Elimina le colonne specificate\n",
    "dataset1 = dataset1.drop(columns=['DATAFLOW', 'LAST UPDATE','s_adj', 'freq', 'cpa2_1', 'CONF_STATUS'])\n",
    "\n",
    "# Filtra le righe dove OBS_FLAG è vuoto (rimuove righe con flag)\n",
    "#dataset = dataset[dataset['OBS_FLAG'].isna() | (dataset['OBS_FLAG'] == '')]\n",
    "\n",
    "dataset1=dataset1.drop(columns=['OBS_FLAG'])\n",
    "\n",
    "\n",
    "dataset1 = dataset1.fillna(dataset.mean(numeric_only=True))\n",
    "\n",
    "print(dataset1)"
   ],
   "id": "3b2ce80c9cbd9cf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Crea la colonna 'serie' solo con 'geo' (dato che cpa2_1 è eliminata)\n",
    "dataset1['serie'] = dataset1['geo']\n",
    "\n",
    "\n",
    "# Crea la tabella pivot\n",
    "pivot_df = dataset1.pivot_table(index='TIME_PERIOD', columns='serie', values='OBS_VALUE')\n",
    "\n",
    "print(pivot_df)"
   ],
   "id": "d2c0c919f15b6ff3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:26:00.015231500Z",
     "start_time": "2025-05-22T16:22:01.274060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "## 1. Trasposizione\n",
    "data = pivot_df.T\n",
    "\n",
    "# 2. Rimuove righe completamente vuote\n",
    "data = data.dropna(how='all')\n",
    "\n",
    "# 3. Imputazione: riempi i NaN con la media di ogni riga\n",
    "data_filled = data.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "\n",
    "# 4. Rimuovi righe che ancora hanno tutti NaN (es. Media era NaN)\n",
    "data_filled = data_filled.dropna()\n",
    "\n",
    "# 5. Controlla che siano rimaste almeno 2 righe\n",
    "if data_filled.shape[0] < 2:\n",
    "    print(\"Errore: troppo poche righe per il clustering.\")\n",
    "else:\n",
    "    # 6. Standardizzazione\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_filled)\n",
    "\n",
    "    # 7. Clustering con silhouette\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_score\n",
    "\n",
    "    best_k = 10\n",
    "    best_score = -1\n",
    "\n",
    "    for k in range(2, min(11, data_scaled.shape[0] + 1)):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(data_scaled)\n",
    "        score = silhouette_score(data_scaled, labels)\n",
    "        print(f\"Silhouette score per k={k}: {score:.3f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    print(f\"\\nMiglior numero di cluster: {best_k} con Silhouette Score = {best_score:.3f}\")\n",
    "\n",
    "    # Applica KMeans finale\n",
    "    kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "\n"
   ],
   "id": "80aff56c5e8bc292",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score per k=2: 0.461\n",
      "Silhouette score per k=3: 0.483\n",
      "Silhouette score per k=4: 0.474\n",
      "Silhouette score per k=5: 0.313\n",
      "Silhouette score per k=6: 0.341\n",
      "Silhouette score per k=7: 0.312\n",
      "Silhouette score per k=8: 0.332\n",
      "Silhouette score per k=9: 0.291\n",
      "Silhouette score per k=10: 0.261\n",
      "\n",
      "Miglior numero di cluster: 3 con Silhouette Score = 0.483\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:26:00.016232Z",
     "start_time": "2025-05-22T16:22:01.754770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Crea un DataFrame con le serie originali\n",
    "clustered_df = pd.DataFrame(data_filled)\n",
    "clustered_df['cluster'] = labels\n"
   ],
   "id": "5b9087cbdc0a005",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:26:00.018238Z",
     "start_time": "2025-05-22T16:22:01.822172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    print(f\"\\nCluster {i}\")\n",
    "    print(clustered_df[clustered_df['cluster'] == i].index.tolist())\n"
   ],
   "id": "7a513eac140079e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['AL', 'AT', 'BE', 'BG', 'CH', 'CY', 'CZ', 'DK', 'EE', 'EL', 'EU27_2020', 'FI', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'ME', 'MK', 'MT', 'NL', 'NO', 'PL', 'PT', 'RO', 'SE', 'SI', 'SK', 'TR']\n",
      "\n",
      "Cluster 1\n",
      "['DE', 'EA19', 'EA20', 'ES', 'FR', 'RS', 'UK']\n",
      "\n",
      "Cluster 2\n",
      "['BA', 'UA']\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
